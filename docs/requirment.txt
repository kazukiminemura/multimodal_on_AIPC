# Stable Diffusion Service Requirements

## 1. Goals
- Deliver an offline-friendly image generation service powered exclusively by **OpenVINO/stable-diffusion-v1-5-int8-ov**.
- Provide a simple REST API plus a bundled UI so users can craft prompts and review outputs entirely on local hardware (Intel AI PC or compatible).
- Offer predictable operations tooling: health checks, optional mock mode, and scripted model downloads.

## 2. Target Users
- Makers and developers experimenting with OpenVINO Stable Diffusion on their own devices.
- Designers who need quick, private ideation drafts without sending prompts to external clouds.
- Educators demonstrating diffusion workflows in constrained or offline environments.

## 3. Functional Requirements
### 3.1 Image Generation API
- Expose `POST /image` accepting prompt parameters (`prompt`, `negative_prompt`, `num_inference_steps`, `guidance_scale`, `seed`, `width`, `height`).
- Return `ImageGenerationResponse` with job metadata, URLs, provider identifier, and mock flag.
- Reject invalid payloads via Pydantic validation and return descriptive HTTP errors.

### 3.2 Health & Operations
- Expose `GET /health` reporting `status`, `use_mocks`, `auto_download_models`, `cached_models`, and Stable Diffusion details.
- Log model download attempts, inference requests, and errors with contextual metadata.
- Allow optional mock mode (`USE_MOCKS=true`) to keep the UI interactive when no inference server is available.

### 3.3 Model Management
- On startup (when `AUTO_DOWNLOAD_MODELS=true`), ensure the Stable Diffusion snapshot exists under `data/models/stable-diffusion`.
- Provide `python download_models.py` to force downloads regardless of mock configuration.
- Respect `HUGGINGFACE_TOKEN` when gated repos require authentication.

### 3.4 User Interface
- Serve static assets (`index.html`, `chat.js`, `style.css`) that let users submit prompts, tweak parameters, and view recent generations.
- Persist a small gallery history per session using browser storage.
- Indicate request status (ready, generating, error) in the footer.

## 4. Non-functional Requirements
- Operate entirely offline once models are cached and a local inference endpoint is available.
- Complete typical 512Ã—512 generations within ~20 s on recommended hardware; surface timeouts gracefully.
- Keep the codebase readable and modular for future feature additions (safety filters, gallery downloads, etc.).

## 5. Technical Constraints
- Backend: Python 3.10+ with FastAPI, Uvicorn, httpx, Pydantic, pydantic-settings, huggingface-hub.
- Stable Diffusion runtime: OpenVINO execution of the quantized v1.5 model reachable via an OpenAI-compatible HTTP endpoint.
- Frontend: static HTML/CSS/JavaScript served directly by FastAPI; no build tools required.

## 6. Setup Flow
1. Clone the repository and create a Python virtual environment.
2. Install dependencies with `pip install -r requirements.txt`.
3. Optionally stage weights via `python download_models.py` (requires Hugging Face credentials when gated).
4. Launch `uvicorn main:app --reload` and open `http://127.0.0.1:8000/`.
5. Configure the Stable Diffusion inference endpoint via environment variables as needed.

## 7. Future Enhancements
- Add safety filters and NSFW detection before returning generated images.
- Support batch generation and job queue monitoring.
- Provide export options (zip downloads, shareable links) for the gallery.
- Integrate authentication and rate limiting for multi-user deployments.
